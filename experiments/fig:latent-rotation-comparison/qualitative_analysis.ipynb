{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from rae import PROJECT_ROOT\n",
    "from rae.modules.enumerations import Output\n",
    "from rae.pl_modules.pl_gautoencoder import LightningAutoencoder\n",
    "\n",
    "try:\n",
    "    # be ready for 3.10 when it drops\n",
    "    from enum import StrEnum\n",
    "except ImportError:\n",
    "    from backports.strenum import StrEnum\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tueplots import bundles\n",
    "from tueplots import figsizes\n",
    "\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "DEVICE: str = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rae.modules.text.encoder import GensimEncoder\n",
    "\n",
    "ENCODERS = {\n",
    "    model_name: GensimEncoder(language=\"en\", lemmatize=False, model_name=model_name)\n",
    "    for model_name in (\n",
    "        \"local_fasttext\",\n",
    "        \"word2vec-google-news-300\",\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "seed_everything(4)\n",
    "\n",
    "NUM_ANCHORS = 300\n",
    "NUM_TARGETS = 200\n",
    "NUM_CLUSTERS = 4\n",
    "WORDS = sorted(ENCODERS[\"local_fasttext\"].model.key_to_index.keys())\n",
    "WORDS = [word for word in WORDS if word.isalpha() and len(word) >= 4]\n",
    "TARGET_WORDS = [\"school\", \"ferrari\", \"water\", \"martial\"]  # words to take the neighborhoods from\n",
    "# TARGET_WORDS = random.sample(WORDS, NUM_CLUSTERS)\n",
    "print(f\"{TARGET_WORDS=}\")\n",
    "word2index = {word: i for i, word in enumerate(WORDS)}\n",
    "TARGETS = torch.zeros(len(WORDS), device=\"cpu\")\n",
    "target_cluster = [\n",
    "    [word for word, sim in ENCODERS[\"local_fasttext\"].model.most_similar(target_word, topn=NUM_TARGETS)]\n",
    "    for target_word in TARGET_WORDS\n",
    "]\n",
    "\n",
    "valid_words, valid_targets = [], []\n",
    "for i, target_cluster in enumerate(target_cluster):\n",
    "    valid_words.append(TARGET_WORDS[i])\n",
    "    valid_targets.append(i + 1)\n",
    "    for word in target_cluster:\n",
    "        if word in word2index:\n",
    "            valid_words.append(word)\n",
    "            valid_targets.append(i + 1)\n",
    "\n",
    "WORDS = valid_words\n",
    "TARGETS = valid_targets\n",
    "\n",
    "ANCHOR_WORDS = sorted(random.sample(WORDS, NUM_ANCHORS))  # TODO: stratified\n",
    "\n",
    "ANCHOR_WORDS[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from umap import UMAP\n",
    "from sklearn.manifold import TSNE\n",
    "from enum import auto\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def latents_distance(latents):\n",
    "    assert len(latents) == 2\n",
    "    for x in latents:\n",
    "        assert x.shape[1] == 300\n",
    "\n",
    "    dist = F.pairwise_distance(latents[0], latents[1], p=2).mean()\n",
    "    return f\"{dist:.2f}\"\n",
    "\n",
    "\n",
    "def get_latents(words, encoder: GensimEncoder):\n",
    "    latents = torch.tensor([encoder.model.get_vector(word) for word in words], device=DEVICE)\n",
    "    return latents\n",
    "\n",
    "\n",
    "class Reduction(StrEnum):\n",
    "    PCA = auto()\n",
    "    TSNE = auto()\n",
    "    UMAP = auto()\n",
    "    FIRST_DIMS = auto()\n",
    "\n",
    "\n",
    "def to_df(latents, mode: Reduction = \"pca\"):\n",
    "    if mode == Reduction.PCA:\n",
    "        latents2d = PCA(n_components=2).fit_transform(latents.cpu())\n",
    "    elif mode == Reduction.FIRST_DIMS:\n",
    "        latents2d = latents[:, [0, 1]]\n",
    "    elif mode == Reduction.TSNE:\n",
    "        latents2d = TSNE(n_components=2, init=\"pca\", learning_rate=\"auto\", random_state=42).fit_transform(latents.cpu())\n",
    "    # elif mode == Reduction.UMAP:\n",
    "    #     latents2d = UMAP(n_components=2).fit_transform(latents.cpu())\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"x\": latents2d[:, 0].tolist(),\n",
    "            \"y\": latents2d[:, 1].tolist(),\n",
    "            \"target\": TARGETS,\n",
    "        }\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bg(\n",
    "    ax,\n",
    "    df,\n",
    "    cmap,\n",
    "    norm,\n",
    "    size,\n",
    "    bg_alpha,\n",
    "):\n",
    "    \"\"\"Create and return a plot of all our movie embeddings with very low opacity.\n",
    "    (Intended to be used as a basis for further - more prominent - plotting of a\n",
    "    subset of movies. Having the overall shape of the map space in the background is\n",
    "    useful for context.)\n",
    "    \"\"\"\n",
    "    ax.scatter(df.x, df.y, c=cmap(norm(df[\"target\"])), alpha=bg_alpha, s=size)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def hightlight_cluster(\n",
    "    ax,\n",
    "    df,\n",
    "    target,\n",
    "    alpha,\n",
    "    cmap,\n",
    "    norm,\n",
    "    size=0.5,\n",
    "):\n",
    "    cluster_df = df[df[\"target\"] == target]\n",
    "    ax.scatter(cluster_df.x, cluster_df.y, c=cmap(norm(cluster_df[\"target\"])), alpha=alpha, s=size)\n",
    "\n",
    "\n",
    "def plot_latent_space(ax, df, targets, size, cmap, norm, bg_alpha, alpha):\n",
    "    ax = plot_bg(ax, df, bg_alpha=bg_alpha, cmap=cmap, norm=norm, size=size)\n",
    "    for target in targets:\n",
    "        hightlight_cluster(ax, df, target, alpha=alpha, size=size, cmap=cmap, norm=norm)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_latents = {}\n",
    "anchors_latents = {}\n",
    "for enc_name, encoder in ENCODERS.items():\n",
    "    ae_latents[enc_name] = get_latents(words=WORDS, encoder=encoder)\n",
    "    anchors_latents[enc_name] = get_latents(words=ANCHOR_WORDS, encoder=encoder)\n",
    "\n",
    "import copy\n",
    "\n",
    "original_ae_latents = copy.deepcopy(ae_latents)\n",
    "original_anchor_latents = copy.deepcopy(anchors_latents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDUCTION = Reduction.PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from rae.modules.attention import *\n",
    "\n",
    "\n",
    "col_config = ((None, None),)\n",
    "N_ROWS = len(ENCODERS)\n",
    "N_COLS = len(col_config) + 1\n",
    "print(\n",
    "    N_ROWS,\n",
    "    N_COLS,\n",
    ")\n",
    "plt.rcParams.update(bundles.icml2022())\n",
    "plt.rcParams.update(figsizes.icml2022_full(ncols=N_COLS, nrows=N_ROWS, height_to_width_ratio=1.0))\n",
    "\n",
    "import matplotlib as mpl\n",
    "\n",
    "num_colors = len(TARGET_WORDS)\n",
    "cmap = mpl.colors.ListedColormap(plt.cm.get_cmap(\"Set1\", 10).colors[:num_colors], name=\"rgb\", N=num_colors)\n",
    "norm = plt.Normalize(min(TARGETS), max(TARGETS))\n",
    "\n",
    "fig, axes = plt.subplots(dpi=300, nrows=N_ROWS, ncols=N_COLS, sharey=True, sharex=True, squeeze=True)\n",
    "\n",
    "S = 7\n",
    "BG_ALPHA = 0.35\n",
    "ALPHA = 0.5\n",
    "\n",
    "TARGET_HIGHLIGHT = [1]\n",
    "for ax_encoders, (_, latents) in zip(axes[0], ae_latents.items()):\n",
    "\n",
    "    plot_latent_space(\n",
    "        ax_encoders,\n",
    "        to_df(latents, mode=REDUCTION),\n",
    "        targets=TARGET_HIGHLIGHT,\n",
    "        size=S,\n",
    "        bg_alpha=BG_ALPHA,\n",
    "        alpha=ALPHA,\n",
    "        cmap=cmap,\n",
    "        norm=norm,\n",
    "    )\n",
    "\n",
    "distances = {\"absolute\": latents_distance(list(ae_latents.values()))}\n",
    "\n",
    "for col_i, (quant_mode, bin_size) in enumerate(col_config):\n",
    "    rel_attention = RelativeAttention(\n",
    "        n_anchors=NUM_ANCHORS,\n",
    "        n_classes=len(set(TARGETS)),\n",
    "        similarity_mode=RelativeEmbeddingMethod.INNER,\n",
    "        values_mode=ValuesMethod.SIMILARITIES,\n",
    "        normalization_mode=NormalizationMode.L2,\n",
    "    )\n",
    "    assert sum(x.numel() for x in rel_attention.parameters()) == 0\n",
    "    rels = []\n",
    "    for row_ax, (enc_name, latents), (a_enc_name, a_latents) in zip(\n",
    "        axes[1], ae_latents.items(), anchors_latents.items()\n",
    "    ):\n",
    "        assert enc_name == a_enc_name\n",
    "        rel = rel_attention(x=latents, anchors=a_latents)[AttentionOutput.SIMILARITIES]\n",
    "        rels.append(rel)\n",
    "        plot_latent_space(\n",
    "            row_ax,\n",
    "            to_df(rel, mode=REDUCTION),\n",
    "            targets=TARGET_HIGHLIGHT,\n",
    "            size=S,\n",
    "            bg_alpha=BG_ALPHA,\n",
    "            alpha=ALPHA,\n",
    "            cmap=cmap,\n",
    "            norm=norm,\n",
    "        )\n",
    "    distances[f\"relative({quant_mode}, {bin_size})\"] = latents_distance(rels)\n",
    "\n",
    "distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name: str = f\"word-embeddings-qualitative-{REDUCTION}\"\n",
    "file_name_pdf: str = f\"{file_name}.pdf\"\n",
    "file_name_svg: str = f\"{file_name}.svg\"\n",
    "\n",
    "fig.savefig(f\"{file_name}.svg\", bbox_inches=\"tight\")\n",
    "!rsvg-convert -f pdf -o $file_name_pdf $file_name_svg\n",
    "!rm $file_name_svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
