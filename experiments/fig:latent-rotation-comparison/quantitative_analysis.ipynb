{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from typing import Mapping, Tuple\n",
    "\n",
    "from rae.openfaiss import FaissIndex\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from pytorch_lightning import seed_everything\n",
    "import numpy as np\n",
    "from rae.modules.attention import *\n",
    "from rae.utils.utils import StrEnum\n",
    "from sklearn.cluster import KMeans\n",
    "from torchmetrics.functional import pairwise_cosine_similarity\n",
    "from nn_core.common import PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE: str = \"cuda\"\n",
    "MODELS = (\n",
    "    \"local_fasttext\",\n",
    "    \"word2vec-google-news-300\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rae.modules.text.encoder import GensimEncoder\n",
    "\n",
    "ENCODERS = {model_name: GensimEncoder(language=\"en\", lemmatize=False, model_name=model_name) for model_name in MODELS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = list(list(ENCODERS.values())[0].model.key_to_index.keys())\n",
    "all_words = [\n",
    "    word for word in all_words[400:] if word.isalpha() and len(word) >= 4\n",
    "]  # skip stopwords (first ~400 words) and filter out non-alpha and short words\n",
    "# random.shuffle(random_words)\n",
    "SEARCH_WORDS = all_words[:20_000]\n",
    "SEARCH_WORDS[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RETRIEVAL_ANCHORS_NUM = 300\n",
    "NUM_SEEDS: int = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latents(words, encoder: GensimEncoder):\n",
    "    latents = torch.stack([torch.tensor(encoder.model.get_vector(word), device=DEVICE) for word in words], dim=0)\n",
    "    return latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rae.modules.attention import *\n",
    "from torch_cluster import fps\n",
    "\n",
    "rel_proj = RelativeAttention(\n",
    "    n_anchors=RETRIEVAL_ANCHORS_NUM,\n",
    "    n_classes=None,\n",
    "    similarity_mode=RelativeEmbeddingMethod.INNER,\n",
    "    values_mode=ValuesMethod.SIMILARITIES,\n",
    "    normalization_mode=NormalizationMode.L2,\n",
    "    #  output_normalization_mode=OutputNormalization.L2,\n",
    "    #          similarities_quantization_mode='differentiable_round',\n",
    "    #          similarities_bin_size=0.01,\n",
    "    #          similarities_num_clusters=,\n",
    "    #         absolute_quantization_mode=\"cluster\",\n",
    "    #         absolute_bin_size=2,  # ignored\n",
    "    #         absolute_num_clusters=2,\n",
    ")\n",
    "\n",
    "\n",
    "class LatentSpace:\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoding_type: str,\n",
    "        encoder: str,\n",
    "        vectors: torch.Tensor = None,\n",
    "    ):\n",
    "        self.encoding_type: str = encoding_type\n",
    "        self.vectors: torch.Tensor = vectors\n",
    "        self.encoder: str = encoder\n",
    "\n",
    "        self._cached_anchors = {}\n",
    "        self._cache_index = None\n",
    "\n",
    "    def to_faiss(self) -> FaissIndex:\n",
    "        if self._cache_index is not None:\n",
    "            return self._cache_index\n",
    "        index: FaissIndex = FaissIndex(d=self.vectors.size(1))\n",
    "\n",
    "        index.add_vectors(\n",
    "            embeddings=list(zip(SEARCH_WORDS, self.vectors.cpu().numpy())),\n",
    "            normalize=True,\n",
    "        )\n",
    "\n",
    "        self._cache_index = index\n",
    "        return index\n",
    "\n",
    "    def to_relative(\n",
    "        self, anchor_choice: str = None, seed: int = None, anchors: Optional[Sequence[str]] = None\n",
    "    ) -> \"RelativeSpace\":\n",
    "        assert self.encoding_type != \"relative\"  # TODO: for now\n",
    "        anchors = self.get_anchors(anchor_choice=anchor_choice, seed=seed) if anchors is None else anchors\n",
    "\n",
    "        anchor_latents: np.ndarray = ENCODERS[self.encoder].model.vectors_for_all(keys=anchors).vectors\n",
    "        anchor_latents: torch.Tensor = torch.as_tensor(anchor_latents)\n",
    "\n",
    "        relative_vectors = rel_proj(x=self.vectors, anchors=anchor_latents.cpu())[AttentionOutput.SIMILARITIES].cpu()\n",
    "        return RelativeSpace(\n",
    "            vectors=relative_vectors,\n",
    "            encoder=self.encoder,\n",
    "            anchors=anchors,\n",
    "        )\n",
    "\n",
    "    def get_anchors(self, anchor_choice: str, seed: int) -> Sequence[str]:\n",
    "        key = (seed, anchor_choice)\n",
    "        if key in self._cached_anchors:\n",
    "            # print(f\"Cache match: {key} in {self._cached_anchors.keys()}\")\n",
    "            return self._cached_anchors[key]\n",
    "        else:\n",
    "            # print(f\"Cache miss: {key} not in {self._cached_anchors.keys()}\")\n",
    "            pass\n",
    "        # Select anchors\n",
    "        seed_everything(seed)\n",
    "        if anchor_choice == \"uniform\" or anchor_choice.startswith(\"top_\"):\n",
    "            limit: int = len(SEARCH_WORDS) if anchor_choice == \"uniform\" else int(anchor_choice[4:])\n",
    "            anchor_set: Sequence[str] = random.sample(SEARCH_WORDS[:limit], RETRIEVAL_ANCHORS_NUM)\n",
    "        elif anchor_choice == \"fps\":\n",
    "            anchor_fps = get_latents(words=SEARCH_WORDS, encoder=ENCODERS[self.encoder])\n",
    "            anchor_fps = F.normalize(anchor_fps, p=2, dim=-1)\n",
    "            anchor_fps = fps(anchor_fps, random_start=True, ratio=RETRIEVAL_ANCHORS_NUM / len(SEARCH_WORDS))\n",
    "            anchor_set: Sequence[str] = [SEARCH_WORDS[word_index] for word_index in anchor_fps.cpu().tolist()]\n",
    "        elif anchor_choice == \"kmeans\":\n",
    "            vectors = F.normalize(get_latents(words=SEARCH_WORDS, encoder=ENCODERS[self.encoder]), p=2)\n",
    "            clustered = KMeans(n_clusters=RETRIEVAL_ANCHORS_NUM).fit_predict(vectors.cpu().numpy())\n",
    "\n",
    "            all_targets = sorted(set(clustered))\n",
    "            cluster2embeddings = {target: vectors[clustered == target] for target in all_targets}\n",
    "            cluster2centroid = {\n",
    "                cluster: centroid.mean(dim=0).cpu().numpy() for cluster, centroid in cluster2embeddings.items()\n",
    "            }\n",
    "            centroids = np.array(list(cluster2centroid.values()), dtype=\"float32\")\n",
    "\n",
    "            index: FaissIndex = FaissIndex(d=vectors.shape[1])\n",
    "            index.add_vectors(list(zip(SEARCH_WORDS, vectors.cpu().numpy())), normalize=False)\n",
    "            centroids = index.search_by_vectors(query_vectors=centroids, k_most_similar=1, normalize=True)\n",
    "\n",
    "            anchor_set = [list(word2score.keys())[0] for word2score in centroids]\n",
    "        else:\n",
    "            assert NotImplementedError\n",
    "\n",
    "        result = sorted(anchor_set)\n",
    "        self._cached_anchors[key] = result\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "class RelativeSpace(LatentSpace):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vectors: torch.Tensor,\n",
    "        anchors: Sequence[str],\n",
    "        encoder: str = None,\n",
    "    ):\n",
    "        super().__init__(encoding_type=\"relative\", vectors=vectors, encoder=encoder)\n",
    "        self.anchors: Sequence[str] = anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_CHOICES = (\"uniform\", \"top_1000\", \"top_5000\", \"top_10000\", \"fps\", \"kmeans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rae.cka import CudaCKA as CKA\n",
    "\n",
    "EncPair = Tuple[str, str]\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_retrieval(latent_space1: LatentSpace, latent_space2: LatentSpace, k: int = 5):\n",
    "    performance = {\n",
    "        key: []\n",
    "        for key in (\n",
    "            \"src_enc\",\n",
    "            \"tgt_enc\",\n",
    "            \"topk_jaccard\",\n",
    "            \"mrr\",\n",
    "            \"linear_cka\",\n",
    "            \"rbf_kernel_cka\",\n",
    "            \"mse\",\n",
    "            \"cosine_sim\",\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # index1: FaissIndex = latent_space1.to_faiss()\n",
    "    index2: FaissIndex = latent_space2.to_faiss()\n",
    "\n",
    "    target_neighbors = index2.search_by_vectors(\n",
    "        query_vectors=latent_space2.vectors.cpu().numpy(), k_most_similar=k, normalize=True\n",
    "    )\n",
    "    actual_neighbors = index2.search_by_vectors(\n",
    "        query_vectors=latent_space1.vectors.cpu().numpy(), k_most_similar=k, normalize=True\n",
    "    )\n",
    "\n",
    "    target_neighbors: Mapping[str, Mapping[str, float]] = {\n",
    "        word: topk for word, topk in zip(SEARCH_WORDS, target_neighbors)\n",
    "    }\n",
    "    actual_neighbors: Mapping[str, Mapping[str, float]] = {\n",
    "        word: topk for word, topk in zip(SEARCH_WORDS, actual_neighbors)\n",
    "    }\n",
    "\n",
    "    target_words: Mapping[str, Set[str]] = {\n",
    "        search_word: set(target_neighbors[search_word].keys()) for search_word in SEARCH_WORDS\n",
    "    }\n",
    "    actual_words: Mapping[str, Set[str]] = {\n",
    "        search_word: set(actual_neighbors[search_word].keys()) for search_word in SEARCH_WORDS\n",
    "    }\n",
    "\n",
    "    topk_jaccard = {\n",
    "        search_word: len(set.intersection(target_words[search_word], actual_words[search_word]))\n",
    "        / len(set.union(target_words[search_word], actual_words[search_word]))\n",
    "        for search_word in SEARCH_WORDS\n",
    "    }\n",
    "    topk_jaccard = np.mean(list(topk_jaccard.values()))\n",
    "\n",
    "    search_word2word2rank = {\n",
    "        search_word: {key: index for index, key in enumerate(word2sim.keys(), start=1)}\n",
    "        for search_word, word2sim in actual_neighbors.items()\n",
    "    }\n",
    "    mrr = {\n",
    "        search_word: (\n",
    "            #                 word2rank.get(search_word, K)\n",
    "            0\n",
    "            if search_word not in word2rank\n",
    "            else 1 / word2rank[search_word]\n",
    "        )\n",
    "        for search_word, word2rank in search_word2word2rank.items()\n",
    "    }\n",
    "    mrr = np.mean(list(mrr.values()))\n",
    "\n",
    "    # semantic_horizon = []\n",
    "    # for search_word, neighbors in actual_words.items():\n",
    "    #     neighbor2ranking = {\n",
    "    #         neighbor: {\n",
    "    #             key: index\n",
    "    #             for index, key in enumerate(\n",
    "    #                 enc_type2enc_names2word2topk[\"absolute\"][(enc_name2, enc_name2)][neighbor].keys(), start=1\n",
    "    #             )\n",
    "    #         }\n",
    "    #         for neighbor in neighbors\n",
    "    #     }\n",
    "    #     neighbor2mrr = {\n",
    "    #         neighbor: (\n",
    "    #             #                 topk.get(search_word, K)\n",
    "    #             0\n",
    "    #             if search_word not in ranking\n",
    "    #             else 1 / ranking[search_word]\n",
    "    #         )\n",
    "    #         for neighbor, ranking in neighbor2ranking.items()\n",
    "    #     }\n",
    "    #     semantic_horizon.append(np.mean(list(neighbor2mrr.values())))\n",
    "    #\n",
    "    # semantic_horizon = np.mean(semantic_horizon)\n",
    "\n",
    "    chunk_size: int = 5000\n",
    "    num_chunks: int = (len(SEARCH_WORDS) + chunk_size - 1) // chunk_size\n",
    "    linear_cka, rbf_kernel_cka, mse, cosine_sim = [], [], [], []\n",
    "    for chunk_latents1, chunk_latents2 in zip(\n",
    "        latent_space1.vectors.chunk(num_chunks), latent_space2.vectors.chunk(num_chunks)\n",
    "    ):\n",
    "        chunk_latents1 = chunk_latents1.cuda()\n",
    "        chunk_latents2 = chunk_latents2.cuda()\n",
    "        cka = CKA(device=DEVICE)\n",
    "\n",
    "        chunk_linear_cka = cka.linear_CKA(chunk_latents1, chunk_latents2).cpu()\n",
    "        # chunk_rbf_kernel_cka = cka.kernel_CKA(chunk_latents1, chunk_latents2).cpu()\n",
    "        chunk_cosine_sim = F.cosine_similarity(chunk_latents1, chunk_latents2).mean().cpu()\n",
    "        chunk_mse = F.mse_loss(chunk_latents1, chunk_latents2, reduction=\"sum\").cpu()\n",
    "\n",
    "        _ = chunk_latents1.cpu()\n",
    "        _ = chunk_latents2.cpu()\n",
    "\n",
    "        linear_cka.append(chunk_linear_cka)\n",
    "        rbf_kernel_cka.append(torch.zeros(1))\n",
    "        mse.append(chunk_mse)\n",
    "        cosine_sim.append(chunk_cosine_sim)\n",
    "\n",
    "    linear_cka = torch.stack(linear_cka).mean(dim=0).cpu().item()\n",
    "    rbf_kernel_cka = torch.stack(rbf_kernel_cka).mean(dim=0).cpu().item()\n",
    "    mse = torch.stack(mse).mean(dim=0).cpu().item()\n",
    "    cosine_sim = torch.stack(cosine_sim).mean(dim=0).cpu().item()\n",
    "\n",
    "    performance[\"src_enc\"].append(latent_space1.encoder)\n",
    "    performance[\"tgt_enc\"].append(latent_space2.encoder)\n",
    "    performance[\"topk_jaccard\"].append(topk_jaccard)\n",
    "    performance[\"mrr\"].append(mrr)\n",
    "    performance[\"linear_cka\"].append(linear_cka)\n",
    "    performance[\"rbf_kernel_cka\"].append(rbf_kernel_cka)\n",
    "    performance[\"mse\"].append(mse)\n",
    "    performance[\"cosine_sim\"].append(cosine_sim)\n",
    "\n",
    "    performance = pd.DataFrame(performance)\n",
    "    performance[\"enc1_type\"] = latent_space1.encoding_type\n",
    "    performance[\"enc2_type\"] = latent_space2.encoding_type\n",
    "\n",
    "    return performance\n",
    "\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def evaluate(\n",
    "#     enc_type2enc_name2faiss_index: Mapping[str, Mapping[str, FaissIndex]],\n",
    "#     enc_type2enc_names2word2topk: Mapping[str, Mapping[Tuple[str, str], Mapping[str, Sequence[str]]]],\n",
    "# ):\n",
    "#     performance = {key: [] for key in (\"enc_name\", \"linear_cka\", \"rbf_kernel_cka\")}\n",
    "#\n",
    "#     for enc_name in (\"word2vec-google-news-300\", \"local_fasttext\"):\n",
    "#         faiss_abs = enc_type2enc_name2faiss_index[\"absolute\"][enc_name]\n",
    "#         faiss_rel = enc_type2enc_name2faiss_index[\"relative\"][enc_name]\n",
    "#\n",
    "#         linear_cka, rbf_kernel_cka = [], []\n",
    "#         for chunk in chunk_iterable(SEARCH_WORDS, chunk_size=5_000):\n",
    "#             chunk_latents_enc1 = torch.as_tensor(faiss_abs.reconstruct_n(keys=chunk), device=DEVICE)\n",
    "#             chunk_latents_enc2 = torch.as_tensor(faiss_rel.reconstruct_n(keys=chunk), device=DEVICE)\n",
    "#\n",
    "#             cka = CKA(device=DEVICE)\n",
    "#             linear_cka.append(cka.linear_CKA(chunk_latents_enc1, chunk_latents_enc2))\n",
    "#             rbf_kernel_cka.append(cka.kernel_CKA(chunk_latents_enc1, chunk_latents_enc2))\n",
    "#\n",
    "#         linear_cka = torch.stack(linear_cka).mean(dim=0).cpu().item()\n",
    "#         rbf_kernel_cka = torch.stack(rbf_kernel_cka).mean(dim=0).cpu().item()\n",
    "#\n",
    "#         performance[\"enc_name\"].append(enc_name)\n",
    "#         performance[\"linear_cka\"].append(linear_cka)\n",
    "#         performance[\"rbf_kernel_cka\"].append(rbf_kernel_cka)\n",
    "#\n",
    "#     return pd.DataFrame(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performances = []\n",
    "anchor_infos = []\n",
    "for seed, anchor_choice in (pbar := tqdm(list(itertools.product(range(NUM_SEEDS), ANCHOR_CHOICES)))):\n",
    "    absolute_spaces: Sequence[LatentSpace] = [\n",
    "        LatentSpace(\n",
    "            encoding_type=\"absolute\",\n",
    "            vectors=torch.as_tensor(encoder.model.vectors_for_all(keys=SEARCH_WORDS).vectors),\n",
    "            encoder=enc_name,\n",
    "        )\n",
    "        for enc_name, encoder in ENCODERS.items()\n",
    "    ]\n",
    "\n",
    "    for absolute_space in absolute_spaces:\n",
    "        words: Sequence[str] = absolute_space.get_anchors(anchor_choice=anchor_choice, seed=seed)\n",
    "        anchors: torch.Tensor = get_latents(words=words, encoder=ENCODERS[absolute_space.encoder])\n",
    "        anchor_info = {\n",
    "            \"seed\": seed,\n",
    "            \"anchor_choice\": anchor_choice,\n",
    "            \"anchors\": anchors,\n",
    "            \"words\": words,\n",
    "            \"encoder\": absolute_space.encoder,\n",
    "            \"dists\": pairwise_cosine_similarity(anchors, zero_diagonal=False),\n",
    "        }\n",
    "        anchor_infos.append(anchor_info)\n",
    "\n",
    "    for abs_space1, abs_space2 in itertools.product(absolute_spaces, repeat=2):\n",
    "        # absolute\n",
    "        absolute_performance = evaluate_retrieval(latent_space1=abs_space1, latent_space2=abs_space2)\n",
    "\n",
    "        absolute_performance[\"anchor_choice\"] = anchor_choice\n",
    "        absolute_performance[\"seed\"] = seed\n",
    "        performances.append(absolute_performance)\n",
    "\n",
    "        # relative\n",
    "        rel_space1: RelativeSpace = abs_space1.to_relative(seed=seed, anchor_choice=anchor_choice)\n",
    "        rel_space2: RelativeSpace = abs_space2.to_relative(anchors=rel_space1.anchors)\n",
    "        relative_performance = evaluate_retrieval(latent_space1=rel_space1, latent_space2=rel_space2)\n",
    "        relative_performance[\"anchor_choice\"] = anchor_choice\n",
    "        relative_performance[\"seed\"] = seed\n",
    "\n",
    "        performances.append(relative_performance)\n",
    "\n",
    "performances = pd.concat(performances)\n",
    "performances.to_csv(\n",
    "    PROJECT_ROOT / \"experiments\" / \"fig:latent-rotation-comparison\" / \"quantitative_analysis.tsv\", sep=\"\\t\", index=False\n",
    ")\n",
    "torch.save(anchor_infos, PROJECT_ROOT / \"experiments\" / \"fig:latent-rotation-comparison\" / \"anchor_infos.pt\")\n",
    "performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df = pd.read_csv(\n",
    "    PROJECT_ROOT / \"experiments\" / \"fig:latent-rotation-comparison\" / \"quantitative_analysis.tsv\", sep=\"\\t\"\n",
    ")\n",
    "performance_df.groupby([\"anchor_choice\", \"enc1_type\", \"enc1_type\", \"src_enc\", \"tgt_enc\"]).aggregate(\n",
    "    [\n",
    "        np.mean,\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_infos = torch.load(PROJECT_ROOT / \"experiments\" / \"fig:latent-rotation-comparison\" / \"anchor_infos.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
