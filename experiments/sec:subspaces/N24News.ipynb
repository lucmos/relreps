{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acff9ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb6f7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import sklearn.pipeline\n",
    "import torch\n",
    "from nn_core.serialization import load_model, NNCheckpointIO\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, PreTrainedModel, PreTrainedTokenizer, AutoTokenizer\n",
    "from pytorch_lightning import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e9290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rae.data.text import TREC\n",
    "from rae.modules.attention import RelativeAttention, AttentionOutput\n",
    "from rae.pl_modules.pl_text_classifier import LightningTextClassifier\n",
    "from rae import PROJECT_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beedb177",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ckpt(ckpt_path: Path):\n",
    "    return load_model(module_class=LightningTextClassifier, checkpoint_path=ckpt_path, strict=False).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afde0302",
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_VERSION = 0.1\n",
    "\n",
    "device: str = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48e2eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, ClassLabel\n",
    "\n",
    "dataset_path: Path = Path(\"/mnt/data/projects/N24News/nytimes_dataset_full.json\")\n",
    "dataset = load_dataset(\"json\", data_files=str(dataset_path))[\"train\"]\n",
    "\n",
    "dataset = dataset.add_column(name=\"label\", column=dataset[\"section\"])\n",
    "all_labels = sorted(set(dataset[\"label\"]))\n",
    "dataset = dataset.cast_column(\"label\", ClassLabel(names=all_labels))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c65870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_dir: Path = PROJECT_ROOT / \"data\" / \"hf_datasets\"\n",
    "datasets_dir.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dc86e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_field(batch, src_field: str, tgt_field: str, transformation):\n",
    "    data = batch[src_field]\n",
    "    transformed = transformation(data)\n",
    "\n",
    "    return {tgt_field: transformed}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25974f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "import torch\n",
    "\n",
    "\n",
    "def tokenize(texts: Sequence[str], tokenizer):\n",
    "    pass\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def text_encode(texts: Sequence[str], tokenizer, transformer):\n",
    "    encoding = tokenizer(\n",
    "        texts,\n",
    "        return_tensors=\"pt\",\n",
    "        return_special_tokens_mask=True,\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "    ).to(device)\n",
    "    mask = encoding[\"attention_mask\"] * encoding[\"special_tokens_mask\"].bool().logical_not()\n",
    "    del encoding[\"special_tokens_mask\"]\n",
    "\n",
    "    encoding = transformer(**encoding)\n",
    "    encoding = encoding[\"hidden_states\"][-1]\n",
    "\n",
    "    result = []\n",
    "    for sample_encoding, sample_mask in zip(encoding, mask):\n",
    "        result.append(sample_encoding[sample_mask].mean(dim=0).cpu().numpy())\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76b7350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_transformer(transformer_name):\n",
    "    transformer = AutoModel.from_pretrained(transformer_name, output_hidden_states=True, return_dict=True)\n",
    "    transformer.requires_grad_(False).eval()\n",
    "    return transformer, AutoTokenizer.from_pretrained(transformer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b452f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_encoded_dir: Path = datasets_dir / \"N24News\" / \"text_encoded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c824515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import functools\n",
    "\n",
    "transformers = (\"roberta-base\",)\n",
    "fields = (\"body\",)\n",
    "FORCE_COMPUTE: bool = False\n",
    "\n",
    "for transformer_name, src_field in itertools.product(transformers, fields):\n",
    "    tgt_field: str = f\"{src_field}_{transformer_name}\"\n",
    "    if tgt_field not in dataset or FORCE_COMPUTE:\n",
    "        transformer, tokenizer = load_transformer(transformer_name=transformer_name)\n",
    "        transformer = transformer.to(device)\n",
    "        dataset = dataset.map(\n",
    "            functools.partial(\n",
    "                encode_field,\n",
    "                src_field=src_field,\n",
    "                tgt_field=tgt_field,\n",
    "                transformation=functools.partial(\n",
    "                    text_encode,\n",
    "                    transformer=transformer,\n",
    "                    tokenizer=tokenizer,\n",
    "                ),\n",
    "            ),\n",
    "            num_proc=1,\n",
    "            batched=True,\n",
    "            batch_size=32,\n",
    "            desc=f\"text_encoding field <{src_field}> with <{transformer_name}>\",\n",
    "        )\n",
    "        transformer = transformer.cpu()\n",
    "        dataset.set_format(type=\"torch\", columns=[tgt_field], output_all_columns=True)\n",
    "dataset.save_to_disk(str(text_encoded_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510e7e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "dataset = load_from_disk(text_encoded_dir)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7a36e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_encoded_dir: Path = datasets_dir / \"N24News\" / \"image_encoded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e38eb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from timm.data import resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform\n",
    "\n",
    "base_path: Path = Path(\"/mnt/data/projects/N24News/images\")\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def image_encode(images: Sequence[str], transform, encoder):\n",
    "    images = [Image.open(str(base_path / f\"{image}.jpg\")).convert(\"RGB\") for image in images]\n",
    "\n",
    "    images: Sequence[torch.Tensor] = [transform(image) for image in images]\n",
    "    images: torch.Tensor = torch.stack(images, dim=0).to(device)\n",
    "    encoding = encoder(images)\n",
    "\n",
    "    return list(encoding.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310546b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import functools\n",
    "\n",
    "import timm\n",
    "\n",
    "encoders = (\"vit_base_patch16_224\",)\n",
    "FORCE_COMPUTE: bool = False\n",
    "\n",
    "for encoder_name in encoders:\n",
    "    tgt_field: str = f\"image_{encoder_name}\"\n",
    "    if tgt_field not in dataset or FORCE_COMPUTE:\n",
    "        encoder = timm.create_model(encoder_name, pretrained=True, num_classes=0).to(device)\n",
    "        config = resolve_data_config({}, model=encoder)\n",
    "        transform = create_transform(**config)\n",
    "        encoder.eval()\n",
    "        dataset = dataset.map(\n",
    "            functools.partial(\n",
    "                encode_field,\n",
    "                src_field=\"image_id\",\n",
    "                tgt_field=tgt_field,\n",
    "                transformation=functools.partial(\n",
    "                    image_encode,\n",
    "                    transform=transform,\n",
    "                    encoder=encoder,\n",
    "                ),\n",
    "            ),\n",
    "            num_proc=1,\n",
    "            batched=True,\n",
    "            batch_size=64,\n",
    "            desc=f\"image_encoding field <{src_field}> with <{encoder_name}>\",\n",
    "        )\n",
    "        encoder = encoder.cpu()\n",
    "        dataset.set_format(type=\"torch\", columns=[tgt_field], output_all_columns=True)\n",
    "dataset.save_to_disk(str(image_encoded_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8f878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(image_encoded_dir)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0fec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.train_test_split(test_size=0.1, stratify_by_column=\"label\", seed=42)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f130be91",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.save_to_disk(str(datasets_dir / \"N24News\" / \"encoded\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6fe1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_from_disk(str(datasets_dir / \"N24News\" / \"encoded\"))\n",
    "dataset.set_format(type=\"torch\", columns=[\"body_roberta-base\", \"image_vit_base_patch16_224\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20521c93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
