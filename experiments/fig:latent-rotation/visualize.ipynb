{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6d7d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7720bbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from collections import defaultdict\n",
    "from enum import auto\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, Optional, Tuple, Type, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rich\n",
    "import torch\n",
    "import typer\n",
    "from torchmetrics import (\n",
    "    ErrorRelativeGlobalDimensionlessSynthesis,\n",
    "    MeanSquaredError,\n",
    "    MetricCollection,\n",
    "    PeakSignalNoiseRatio,\n",
    "    StructuralSimilarityIndexMeasure,\n",
    ")\n",
    "\n",
    "from rae.modules.enumerations import Output\n",
    "from rae.pl_modules.pl_gautoencoder import LightningAutoencoder\n",
    "\n",
    "try:\n",
    "    # be ready for 3.10 when it drops\n",
    "    from enum import StrEnum\n",
    "except ImportError:\n",
    "    from backports.strenum import StrEnum\n",
    "\n",
    "import hydra\n",
    "from omegaconf import DictConfig, OmegaConf\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "from nn_core.serialization import NNCheckpointIO\n",
    "\n",
    "from rae.data.vision.datamodule import MyDataModule\n",
    "\n",
    "\n",
    "def parse_checkpoint(\n",
    "    module_class: Type[nn.Module],\n",
    "    checkpoint_path: Path,\n",
    "    map_location: Optional[Union[Dict[str, str], str, torch.device, int, Callable]] = None,\n",
    ") -> Tuple[nn.Module, DictConfig]:\n",
    "    if checkpoint_path.name.endswith(\".ckpt.zip\"):\n",
    "        checkpoint = NNCheckpointIO.load(path=checkpoint_path, map_location=map_location)\n",
    "        model = module_class._load_model_state(\n",
    "            checkpoint=checkpoint, metadata=checkpoint.get(\"metadata\", None), strict=False\n",
    "        )\n",
    "        model.eval()\n",
    "        return (\n",
    "            model,\n",
    "            OmegaConf.create(checkpoint[\"cfg\"]),\n",
    "        )\n",
    "    raise ValueError(f\"Wrong checkpoint: {checkpoint_path}\")\n",
    "\n",
    "\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "EXPERIMENT_ROOT = Path(\".\").parent\n",
    "EXPERIMENT_CHECKPOINTS = EXPERIMENT_ROOT / \"checkpoints\"\n",
    "PREDICTIONS_TSV = EXPERIMENT_ROOT / \"predictions.tsv\"\n",
    "PERFORMANCE_TSV = EXPERIMENT_ROOT / \"performance.tsv\"\n",
    "\n",
    "DATASET_SANITY = {\n",
    "    \"mnist\": (\"rae.data.vision.mnist.MNISTDataset\", \"test\"),\n",
    "    \"fmnist\": (\"rae.data.vision.fmnist.FashionMNISTDataset\", \"test\"),\n",
    "    \"cifar10\": (\"rae.data.vision.cifar10.CIFAR10Dataset\", \"test\"),\n",
    "    \"cifar100\": (\"rae.data.vision.cifar100.CIFAR100Dataset\", \"test\"),\n",
    "}\n",
    "MODEL_SANITY = {\n",
    "    \"abs\": \"rae.modules.vision.resnet.ResNet\",\n",
    "    \"rel\": \"rae.modules.vision.relresnet.RelResNet\",\n",
    "}\n",
    "\n",
    "\n",
    "def parse_checkpoint_id(ckpt: Path) -> str:\n",
    "    return ckpt.with_suffix(\"\").with_suffix(\"\").name\n",
    "\n",
    "\n",
    "# Parse checkpoints tree\n",
    "checkpoints = defaultdict(dict)\n",
    "RUNS = defaultdict(dict)\n",
    "for dataset_abbrv in (\n",
    "    dataset_abbrv for dataset_abbrv in sorted(EXPERIMENT_CHECKPOINTS.iterdir()) if dataset_abbrv.is_dir()\n",
    "):\n",
    "    checkpoints[dataset_abbrv.name] = defaultdict(list)\n",
    "    RUNS[dataset_abbrv.name] = defaultdict(list)\n",
    "    for model_abbrv in sorted(dataset_abbrv.iterdir()):\n",
    "        for ckpt in sorted(model_abbrv.iterdir()):\n",
    "            checkpoints[dataset_abbrv.name][model_abbrv.name].append(ckpt)\n",
    "            RUNS[dataset_abbrv.name][model_abbrv.name].append(parse_checkpoint_id(ckpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(ckpt):\n",
    "    _, cfg = parse_checkpoint(\n",
    "        module_class=PL_MODULE,\n",
    "        checkpoint_path=MODELS[0],\n",
    "        map_location=\"cpu\",\n",
    "    )\n",
    "    datamodule: MyDataModule = hydra.utils.instantiate(cfg.nn.data, _recursive_=False)\n",
    "    datamodule.setup()\n",
    "    val_dataset = datamodule.val_datasets[0]\n",
    "    return val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0b3e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def get_latents(images_batch, ckpt, pca=None):\n",
    "    model, _ = parse_checkpoint(\n",
    "        module_class=PL_MODULE,\n",
    "        checkpoint_path=ckpt,\n",
    "        map_location=\"cpu\",\n",
    "    )\n",
    "    latents = model(images_batch)[Output.DEFAULT_LATENT].detach()\n",
    "    p = torch.randperm(latents.shape[0])\n",
    "    latents = latents[p]\n",
    "    if latents.shape[-1] == 2:\n",
    "        latents2d = latents\n",
    "    else:\n",
    "        if pca is None:\n",
    "            pca = PCA(n_components=2)\n",
    "            pca.fit(latents)\n",
    "\n",
    "        latents2d = pca.transform(latents)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"x\": latents2d[:, 0].tolist(),\n",
    "            \"y\": latents2d[:, 1].tolist(),\n",
    "            \"class\": [classes[i] for i in p],\n",
    "            \"target\": [targets[i] for i in p],\n",
    "            \"index\": [indexes[i] for i in p],\n",
    "        }\n",
    "    )\n",
    "    return df, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc9efb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bg(\n",
    "    ax,\n",
    "    df,\n",
    "    size=0.5,\n",
    "    bg_alpha=0.01,\n",
    "):\n",
    "    \"\"\"Create and return a plot of all our movie embeddings with very low opacity.\n",
    "    (Intended to be used as a basis for further - more prominent - plotting of a\n",
    "    subset of movies. Having the overall shape of the map space in the background is\n",
    "    useful for context.)\n",
    "    \"\"\"\n",
    "    ax.scatter(df.x, df.y, c=cmap(norm(df[\"target\"])), alpha=bg_alpha, s=size)\n",
    "    return ax\n",
    "\n",
    "\n",
    "def hightlight_cluster(\n",
    "    ax,\n",
    "    df,\n",
    "    target,\n",
    "    alpha,\n",
    "    size=0.5,\n",
    "):\n",
    "    cluster_df = df[df[\"target\"] == target]\n",
    "    ax.scatter(cluster_df.x, cluster_df.y, c=cmap(norm(cluster_df[\"target\"])), alpha=alpha, s=size)\n",
    "\n",
    "\n",
    "def plot_latent_space(ax, df, targets, size, bg_alpha=0.1, alpha=0.5):\n",
    "    ax = plot_bg(ax, df, bg_alpha=bg_alpha)\n",
    "    for target in targets:\n",
    "        hightlight_cluster(ax, df, target, alpha=alpha, size=size)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad999176",
   "metadata": {},
   "source": [
    "# Latent Rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3862bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = checkpoints[\"mnist\"][\"nososmall_ae\"]\n",
    "MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7b9500",
   "metadata": {},
   "outputs": [],
   "source": [
    "PL_MODULE = LightningAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9c155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "targets = []\n",
    "indexes = []\n",
    "classes = []\n",
    "\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "seed_everything(0)\n",
    "\n",
    "val_dataset = get_dataset(MODELS[0])\n",
    "K = 5_000\n",
    "idxs = torch.randperm(len(val_dataset))[:K]\n",
    "\n",
    "for idx in idxs:\n",
    "    sample = val_dataset[idx]\n",
    "    indexes.append(sample[\"index\"].item())\n",
    "    images.append(sample[\"image\"])\n",
    "    targets.append(sample[\"target\"])\n",
    "    classes.append(sample[\"class\"])\n",
    "\n",
    "images_batch = torch.stack(images, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119d3971",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_latents_df = []\n",
    "for ckpt in MODELS:\n",
    "    df, _ = get_latents(images_batch, ckpt)\n",
    "    all_latents_df.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cd71a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TO_CONSIDER = range(len(all_latents_df))\n",
    "latents_df = [all_latents_df[i] for i in TO_CONSIDER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea5f75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tueplots import bundles\n",
    "\n",
    "plt.rcParams.update(bundles.icml2022())\n",
    "N_ROWS = 2\n",
    "N_COLS = len(latents_df) // 2\n",
    "\n",
    "plt.rcParams.update(figsizes.icml2022_full(ncols=N_COLS, nrows=N_ROWS, height_to_width_ratio=1.0))\n",
    "cmap = plt.cm.get_cmap(\"Set1\", 10)\n",
    "norm = plt.Normalize(latents_df[0][\"target\"].min(), latents_df[0][\"target\"].max())\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(dpi=150, nrows=N_ROWS, ncols=N_COLS, sharey=True, sharex=True, squeeze=True)\n",
    "\n",
    "for i, row in enumerate(axes):\n",
    "    for j, ax in enumerate(row):\n",
    "        ax.set_aspect(\"equal\")\n",
    "        plot_latent_space(ax, all_latents_df[i * N_COLS + j], targets=[0, 4], size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecd58bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TO_CONSIDER = [4, 6, 5, 8]\n",
    "chosen_latents_df = [all_latents_df[i] for i in TO_CONSIDER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faee89b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tueplots import bundles\n",
    "\n",
    "plt.rcParams.update(bundles.icml2022())\n",
    "N_ROWS = 1\n",
    "N_COLS = len(chosen_latents_df)\n",
    "\n",
    "plt.rcParams.update(figsizes.icml2022_full(ncols=N_COLS, nrows=N_ROWS, height_to_width_ratio=1.0))\n",
    "cmap = plt.cm.get_cmap(\"Set1\", 10)\n",
    "norm = plt.Normalize(latents_df[0][\"target\"].min(), latents_df[0][\"target\"].max())\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(dpi=150, nrows=N_ROWS, ncols=N_COLS, sharey=True, sharex=True, squeeze=True)\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.set_aspect(\"equal\")\n",
    "    plot_latent_space(ax, chosen_latents_df[i], targets=[0, 2], size=0.75, bg_alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf5a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"latent_rotation.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2575b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rsvg-convert -f pdf -o latent_rotation.pdf latent_rotation.svg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241eed6e",
   "metadata": {},
   "source": [
    "# Latent Rotations\n",
    "\n",
    "Single PCA proof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec695bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = checkpoints[\"mnist\"][\"ae\"]\n",
    "PL_MODULE = LightningAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b5ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "targets = []\n",
    "indexes = []\n",
    "classes = []\n",
    "\n",
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "seed_everything(0)\n",
    "\n",
    "val_dataset = get_dataset(MODELS[0])\n",
    "K = 5_000\n",
    "idxs = torch.randperm(len(val_dataset))[:K]\n",
    "\n",
    "for idx in idxs:\n",
    "    sample = val_dataset[idx]\n",
    "    indexes.append(sample[\"index\"].item())\n",
    "    images.append(sample[\"image\"])\n",
    "    targets.append(sample[\"target\"])\n",
    "    classes.append(sample[\"class\"])\n",
    "\n",
    "images_batch = torch.stack(images, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df00135",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents_single_pca = []\n",
    "pca = None\n",
    "for ckpt in MODELS:\n",
    "    df, pca = get_latents(images_batch, ckpt, pca)\n",
    "    latents_single_pca.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79ed58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "latents_independent_pca = []\n",
    "pca = None\n",
    "for ckpt in MODELS:\n",
    "    df, _ = get_latents(images_batch, ckpt, None)\n",
    "    latents_independent_pca.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c524e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "TO_CONSIDER = [0, 1, 2, 3, 4, 5][: len(all_latents_df)]\n",
    "latents_single_pca = [latents_single_pca[i] for i in TO_CONSIDER]\n",
    "latents_independent_pca = [latents_independent_pca[i] for i in TO_CONSIDER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5c8029",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tueplots import figsizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494cc99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tueplots import bundles\n",
    "\n",
    "import distinctipy\n",
    "import matplotlib as mpl\n",
    "\n",
    "plt.rcParams.update(bundles.icml2022())\n",
    "N_ROWS = 1\n",
    "N_COLS = len(latents_single_pca)\n",
    "\n",
    "plt.rcParams.update(figsizes.icml2022_full(ncols=N_COLS, nrows=N_ROWS, height_to_width_ratio=1.0))\n",
    "\n",
    "cmap = plt.cm.get_cmap(\"Set1\", 10)\n",
    "norm = plt.Normalize(latents_single_pca[0][\"target\"].min(), latents_single_pca[0][\"target\"].max())\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    ncols=N_COLS,\n",
    "    nrows=N_ROWS,\n",
    "    sharey=True,\n",
    "    sharex=True,\n",
    "    squeeze=True,\n",
    ")\n",
    "\n",
    "for j, (ax, df) in enumerate(zip(axes, latents_independent_pca)):\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_title(f\"Train {j}\")\n",
    "    plot_latent_space(\n",
    "        ax,\n",
    "        df,\n",
    "        targets=[\n",
    "            0,\n",
    "            1,\n",
    "        ],\n",
    "        size=0.5,\n",
    "        bg_alpha=0.1,\n",
    "        alpha=0.7,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a049d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"pca-proof-row1.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c427ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(\n",
    "    ncols=N_COLS,\n",
    "    nrows=N_ROWS,\n",
    "    sharey=False,\n",
    "    sharex=False,\n",
    "    squeeze=True,\n",
    ")\n",
    "\n",
    "for j, (ax, df) in enumerate(zip(axes, latents_single_pca)):\n",
    "    ax.set_aspect(\"equal\")\n",
    "    plot_latent_space(\n",
    "        ax,\n",
    "        df,\n",
    "        targets=[\n",
    "            0,\n",
    "            1,\n",
    "        ],\n",
    "        size=0.5,\n",
    "        bg_alpha=0.1,\n",
    "        alpha=0.7,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5473c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"pca-proof-row2.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94a0ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rsvg-convert -f pdf -o pca-proof-row1.pdf pca-proof-row1.svg\n",
    "!rsvg-convert -f pdf -o pca-proof-row2.pdf pca-proof-row2.svg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7272da5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
